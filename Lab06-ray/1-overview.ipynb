{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8433c868",
   "metadata": {},
   "source": [
    "# Chapter 1: An Overview of Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ba1cd",
   "metadata": {},
   "source": [
    "One of the reasons we need efficient distributed computing is that we're collecting ever\n",
    "more data with a large variety at increasing speeds.\n",
    "The storage systems, data processing and analytics engines that have emerged in the last decade\n",
    "are crucially important to the success of many companies.\n",
    "Interestingly, most \"big data\" technologies are built for and operated by (data) engineers,\n",
    "that are in charge of data collection and processing tasks.\n",
    "The rationale is to free up data scientists to do what they're best at.\n",
    "As a data science practitioner you might want to focus on training complex machine learning models,\n",
    "running efficient hyperparameter selection, building entirely new and custom models or simulations,\n",
    "or serving your models to showcase them.\n",
    "At the same time you simply might _have to_ scale them to a compute cluster.\n",
    "To do that, the distributed system of your choice needs to support all of these fine-grained\n",
    "\"big compute\" tasks, potentially on specialized hardware.\n",
    "Ideally, it also fits into the big data tool chain you're using and is fast enough to meet your latency requirements.\n",
    "In other words, distributed computing has to be powerful and flexible enough for complex data\n",
    "science workloads, and Ray can help you with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8069a097",
   "metadata": {},
   "source": [
    "Python is likely the most popular language for data science today, and it's certainly\n",
    "the one I find the most useful for my daily work.\n",
    "By now it's over 30 years old, but has a still growing and active community.\n",
    "The rich PyData ecosystem is an essential part of a data scientist's toolbox.\n",
    "How can you make sure to scale out your workloads while still leveraging the tools you need?\n",
    "That's a difficult problem, especially since communities can't be forced to just toss their toolbox,\n",
    "or programming language.\n",
    "That means distributed computing tools for data science have to be built for their existing community."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61176853",
   "metadata": {},
   "source": [
    "## What is Ray?\n",
    "What I like about Ray is that it checks all the above boxes.\n",
    "It's a flexible distributed computing framework build for the Python data science community.\n",
    "Ray is easy to get started and keeps simple things simple.\n",
    "Its core API is as lean as it gets and helps you reason effectively about the distributed programs you want to write.\n",
    "You can efficiently parallelize Python programs on your laptop, and run the code you tested\n",
    "locally on a cluster practically without any changes.\n",
    "Its high-level libraries are easy to configure and can seamlessly be used together.\n",
    "Some of them, like Ray's reinforcement learning library, would have a bright future as standalone\n",
    "projects, distributed or not.\n",
    "While Ray's core is built in C++, it's been a Python-first framework since day one, integrates with many\n",
    "important data science tools, and can count on a growing ecosystem.\n",
    "Distributed Python is not new, and Ray is not the first framework in this space (nor will it be the last),\n",
    "but it is special in what it has to offer.\n",
    "Ray is particularly strong when you combine several of its modules and have custom, machine learning heavy\n",
    "workloads that would be difficult to implement otherwise.\n",
    "It makes distributed computing easy enough to run your complex workloads flexibly by leveraging\n",
    "the Python tools you know and want to use.\n",
    "In other words, by _learning Ray_ you get to know _flexible distributed Python for data science_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21108823",
   "metadata": {},
   "source": [
    "In this chapter you'll get a first glimpse at what Ray can do for you.\n",
    "We will discuss the three layers that make up Ray, namely its core engine, its high-level libraries and its ecosystem.\n",
    "Throughout the chapter we'll show you first code examples to give you a feel for Ray,\n",
    "but we defer any in-depth treatment of Ray's APIs and components to later chapters.\n",
    "You can view this chapter as an overview of the whole book as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5f391",
   "metadata": {},
   "source": [
    "![Ray Layers](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ray_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8f24c4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## A distributed computing framework\n",
    "At its core, Ray is a distributed computing framework.\n",
    "We'll  provide you with just the basic terminology here, and talk about Ray's architecture in depth in chapter 2.\n",
    "In short, Ray sets up and manages clusters of computers so that you can run distributed tasks on them.\n",
    "A ray cluster consists of nodes that are connected to each other via a network.\n",
    "You program against the so-called _driver_, the program root, which lives on the _head node_.\n",
    "The driver can run _jobs_, that is a collection of tasks, that are run on the nodes in the cluster.\n",
    "Specifically, the individual tasks of a job are run on _worker_ processes on _worker nodes_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f9fc2",
   "metadata": {},
   "source": [
    "![Ray cluster](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/simple_cluster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e840a93",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "What's interesting is that a Ray cluster can also be a _local cluster_, i.e. a cluster\n",
    "consisting just of your own computer.\n",
    "In this case, there's just one node, namely the head node, which has the driver process and some worker processes.\n",
    "\n",
    "With that knowledge at hand, it's time to get your hands dirty and run your first local Ray cluster.\n",
    "Installing Ray on any of the major operating systems should work seamlessly using `pip`:\n",
    "\n",
    "```\n",
    "pip install \"ray[rllib, tune, serve]\"\n",
    "```\n",
    "\n",
    "With a simple `pip install ray` you would have installed just the very basics of Ray.\n",
    "Since we want to explore some advanced features, we installed the \"extras\" `rllib` and `tune`,\n",
    "which we'll discuss in a bit.\n",
    "Depending on your system configuration you may not need the quotation marks in the above installation command.\n",
    "\n",
    "Next, go ahead and start a Python session.\n",
    "You could use the `ipython` interpreter, which I find to be the most suitable environment\n",
    "for following along simple examples.\n",
    "The choice is up to you, but in any case please remember to use Python version `3.7` or later.\n",
    "In your Python session you can now easily import and initialize Ray as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bffbb284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 15:37:21,645\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.9.13', ray_version='2.0.0', ray_commit='cba26cc83f6b5b8a2ff166594a65cb74c0ec8740', address_info={'node_ip_address': '192.168.43.126', 'raylet_ip_address': '192.168.43.126', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-10-04_15-37-18_285587_27156/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-10-04_15-37-18_285587_27156/sockets/raylet', 'webui_url': '', 'session_dir': '/tmp/ray/session_2022-10-04_15-37-18_285587_27156', 'metrics_export_port': 53254, 'gcs_address': '192.168.43.126:50564', 'address': '192.168.43.126:50564', 'dashboard_agent_listen_port': 52365, 'node_id': 'eb07ad54b2c1ae0033528e64d2a706ef6108e708b0f091f64e0d3c1c'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag::init[]\n",
    "import ray\n",
    "ray.init()\n",
    "# end::init[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897fe0f5",
   "metadata": {},
   "source": [
    "## Data Processing with Ray Data\n",
    "The first high-level library of Ray we talk about is called \"Ray Data\".\n",
    "This library contains a data structure aptly called `Dataset`, a multitude of connectors for loading data from\n",
    "various formats and systems, an API for transforming such datasets, a way to build data processing pipelines\n",
    "with them, and many integrations with other data processing frameworks.\n",
    "The `Dataset` abstraction builds on the powerful [Arrow framework](https://arrow.apache.org/).\n",
    "\n",
    "To use Ray Data, you need to install Arrow for Python, for instance by running `pip install pyarrow`.\n",
    "We'll now discuss a simple example that creates a distributed `Dataset` on your local Ray cluster from a Python\n",
    "data structure. Specifically, you'll create a dataset from a Python dictionary containing a string `name`\n",
    "and an integer-valued `data` for `10000` entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27871551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '0', 'data': 0}\n",
      "{'name': '1', 'data': 1}\n",
      "{'name': '2', 'data': 2}\n",
      "{'name': '3', 'data': 3}\n",
      "{'name': '4', 'data': 4}\n"
     ]
    }
   ],
   "source": [
    "# tag::ray_data_load[]\n",
    "import ray\n",
    "\n",
    "items = [{\"name\": str(i), \"data\": i} for i in range(10000)]\n",
    "ds = ray.data.from_items(items)   # <1>\n",
    "ds.show(5)  # <2>\n",
    "# end::ray_data_load[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15829ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(num_blocks=200, num_rows=10000, schema={name: string, data: int64})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe988a0a",
   "metadata": {},
   "source": [
    "Great, now you have some distributed rows, but what can you do with that data?\n",
    "The `Dataset` API bets heavily on functional programming, as it is very well suited for data transformations.\n",
    "Even though Python 3 made a point of hiding some of its functional programming capabilities, you're probably\n",
    "familiar with functionality such as `map`, `filter` and others.\n",
    "If not, it's easy enough to pick up.\n",
    "`map` takes each element of your dataset and transforms is into something else, in parallel.\n",
    "`filter` removes data points according to a boolean filter function.\n",
    "And the slightly more elaborate `flat_map` first maps values similarly to `map`, but then also \"flattens\" the result.\n",
    "For instance, if `map` would produce a list of lists, `flat_map` would flatten out the nested lists and give\n",
    "you just a list.\n",
    "Equipped with these three functional API calls, let's see how easily you can transform your dataset `ds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96caf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 15:39:13,800\tWARNING dataset.py:3662 -- The `map`, `flat_map`, and `filter` operations are unvectorized and can be very slow. Consider using `.map_batches()` instead.\n",
      "Map: 100%|██████████| 200/200 [00:01<00:00, 159.38it/s]\n",
      "Filter: 100%|██████████| 200/200 [00:00<00:00, 975.71it/s]\n",
      "Flat_Map: 100%|██████████| 200/200 [00:00<00:00, 1014.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 4, 64, 16, 4096, 36, 46656, 64, 262144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tag::ray_data_transform[]\n",
    "squares = ds.map(lambda x: x[\"data\"] ** 2)  # <1>\n",
    "\n",
    "evens = squares.filter(lambda x: x % 2 == 0)  # <2>\n",
    "evens.count()\n",
    "\n",
    "cubes = evens.flat_map(lambda x: [x, x**3])  # <3>\n",
    "sample = cubes.take(10)  # <4>\n",
    "print(sample)\n",
    "# end::ray_data_transform[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3323f889",
   "metadata": {},
   "source": [
    "The drawback of `Dataset` transformations is that each step gets executed synchronously.\n",
    "In the above example this is a non-issue, but for complex tasks that e.g. mix reading files and processing data,\n",
    "you want an execution that can overlap the individual tasks.\n",
    "`DatasetPipeline` does exactly that.\n",
    "Let's rewrite the last example into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561856e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 15:42:24,805\tINFO dataset.py:3276 -- Created DatasetPipeline with 20 windows: 7390b min, 8000b max, 7944b mean\n",
      "2022-10-04 15:42:24,807\tINFO dataset.py:3286 -- Blocks per window: 10 min, 10 max, 10 mean\n",
      "2022-10-04 15:42:24,815\tWARNING dataset.py:3298 -- ⚠️  This pipeline's parallelism is limited by its blocks per window to ~10 concurrent tasks per window. To maximize performance, increase the blocks per window to at least 12. This may require increasing the base dataset's parallelism and/or adjusting the windowing parameters.\n",
      "2022-10-04 15:42:24,816\tINFO dataset.py:3325 -- ✔️  This pipeline's windows likely fit in object store memory without spilling.\n",
      "Stage 1:   5%|▌         | 1/20 [00:00<00:15,  1.21it/s]\n",
      "Stage 0:  10%|█         | 2/20 [00:00<00:07,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "4\n",
      "64\n",
      "16\n",
      "4096\n",
      "36\n",
      "46656\n",
      "64\n",
      "262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tag::ray_data_pipeline[]\n",
    "pipe = ds.window()  # <1>\n",
    "result = pipe\\\n",
    "    .map(lambda x: x[\"data\"] ** 2)\\\n",
    "    .filter(lambda x: x % 2 == 0)\\\n",
    "    .flat_map(lambda x: [x, x**3])  # <2>\n",
    "result.show(10)\n",
    "# end::ray_data_pipeline[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8812a2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetPipeline(num_windows=20, num_stages=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a35ea5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Reinforcement Learning with Ray RLlib\n",
    "We'll look at a fairly classical control problem of balancing a pendulum.\n",
    "Imagine you have a pendulum like the one in the following figure, fixed at as single point and subject to gravity.\n",
    "You can manipulate that pendulum by giving it a push from the left or the right.\n",
    "If you assert just the right amount of force, the pendulum might remain in an upright position.\n",
    "That's our goal - and the question is whether we can teach a reinforcement learning algorithm to do so for us.\n",
    "\n",
    "# ![Pendulum problem](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/pendulum.png)\n",
    "\n",
    "Specifically, we want to train a reinforcement learning agent that can push to the left or right,\n",
    "thereby acting on its environment (manipulating the pendulum) to reach the \"upright position\" goal\n",
    "for which it will be rewarded.\n",
    "To tackle this problem with Ray RLlib, store the following content in a file called `pendulum.yml`:\n",
    "\n",
    "```yaml\n",
    "pendulum-ppo:\n",
    "  env: Pendulum-v1  # <1>\n",
    "  run: PPO  # <2>\n",
    "  checkpoint_freq: 5  # <3>\n",
    "  stop:\n",
    "    episode_reward_mean: -800  # <4>\n",
    "  config:\n",
    "    lambda: 0.1  # <5>\n",
    "    gamma: 0.95\n",
    "    lr: 0.0003\n",
    "    num_sgd_iter: 6\n",
    "```\n",
    "\n",
    "The details of this configuration file don't matter much at this point, don't get distracted by them.\n",
    "The important part is that you specify the built-in `Pendulum-v1` environment and sufficient RL-specific\n",
    "configuration to ensure the training procedure works.\n",
    "The configuration is a simplified version of one of Ray's\n",
    "[tuned examples](https://github.com/ray-project/ray/tree/master/rllib/tuned_examples).\n",
    "We chose this one because it doesn't require any special hardware and finishes in a matter of minutes.\n",
    "If your computer is powerful enough, you can try to run the tuned example as well, which should yield much better\n",
    "results.\n",
    "To train this pendulum example you can now simply run:\n",
    "\n",
    "```shell\n",
    "rllib train -f pendulum.yml\n",
    "```\n",
    "\n",
    "If you want, you can check the output of this Ray program and see how the different metrics evolve during\n",
    "the training procedure.\n",
    "Assuming the training program finished, we can now check how well it worked.\n",
    "To visualize the trained pendulum you need to install one more Python library with `pip install pyglet`.\n",
    "The only other thing you need to figure out is where Ray stored your training progress.\n",
    "When you run `rllib train` for an experiment, Ray will create a unique experiment ID for you and stores\n",
    "results in a sub-folder of `~/ray-results` by default.\n",
    "For the training configuration we used, you should see a folder with results that looks\n",
    "like `~/ray_results/pendulum-ppo/PPO_Pendulum-v1_<experiment_id>`.\n",
    "During the training procedure intermediate model checkpoints get generated in the same folder.\n",
    "For instance, I have a folder on my machine called:\n",
    "\n",
    "```shell\n",
    " ~/ray_results/pendulum-ppo/PPO_Pendulum-v1_20cbf_00000_0_2021-09-24_15-20-03/\\\n",
    "  checkpoint_000029/checkpoint-29\n",
    "```\n",
    "\n",
    "Once you figured out the experiment ID and chose a checkpoint ID (as a rule of thumb the larger the ID, the\n",
    "better the results), you can evaluate the training performance of your pendulum training run like this\n",
    "(we'll explain what `rollout` means in this context in <<chapter_03>> and <<chapter_04>>):\n",
    "\n",
    "```shell\n",
    "rllib rollout \\\n",
    "  ~/ray_results/pendulum-ppo/PPO_Pendulum-v1_<experiment_id> \\\n",
    "  /checkpoint_000<cp-id>/checkpoint-<cp-id> \\\n",
    "  --run PPO --env Pendulum-v1 --steps 2000\n",
    "```\n",
    "\n",
    "You should see an animation of a pendulum controlled by an agent that looks like the figure of the pendulum\n",
    "from earlier.\n",
    "Since we opted for a quick training procedure instead of maximizing performance, you should see the agent\n",
    "struggle with the pendulum exercise.\n",
    "We could have done much better, and if you're interested to scan Ray's tuned examples for the `Pendulum-v1`\n",
    "environment, you'll find an abundance of solutions to this exercise.\n",
    "The point of this example was to show you how simple it can be to train and evaluate\n",
    "reinforcement learning tasks with RLlib, using just two command line calls to `rllib`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be37e9",
   "metadata": {},
   "source": [
    "## Distributed training with Ray Train\n",
    "\n",
    "Ray RLlib is dedicated to reinforcement learning, but what do you do if you need to train models for\n",
    "other types of machine learning, like supervised learning?\n",
    "You can use another Ray library for distributed training in this case, called _Ray Train_.\n",
    "At this point, we don't have built up enough knowledge of frameworks such as `TensorFlow` to give you a\n",
    "concrete and informative example for Ray Train.\n",
    "It also doesn't make sense right now to dive into deep learning or explain what Train is, for that matter.\n",
    "We'll discuss this in chapter 6, when it's time to.\n",
    "But we can at least roughly sketch what a distributed training \"wrapper\" for an ML model would look like.\n",
    "A schematic procedure for running distributed deep learning with Ray Train looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9057d0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# tag::ray_train_sketch[]\n",
    "from ray.train import Trainer\n",
    "\n",
    "\n",
    "def training_function():  # <1>\n",
    "    pass\n",
    "\n",
    "\n",
    "trainer = Trainer(backend=\"tensorflow\", num_workers=4)  # <2>\n",
    "trainer.start()\n",
    "\n",
    "results = trainer.run(training_function)  # <3>\n",
    "trainer.shutdown()\n",
    "# end::ray_train_sketch[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a2e2f0",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Ray Tune\n",
    "Naming things is hard, but the Ray team hit the spot with _Ray Tune_, which you can use to tune all\n",
    "sorts of parameters.\n",
    "Specifically, it was built to find good hyperparameters for machine learning models.\n",
    "The typical setup is as follows:\n",
    "\n",
    "- You want to run an extremely computationally expensive training function. In ML it's not uncommon\n",
    "  to run training procedures that take days, if not weeks, but let's say you're dealing with just a couple of minutes.\n",
    "- As result of training, you compute a so-called objective function. Usually you either want to maximize\n",
    "  your gains or minimize your losses in terms of performance of your experiment.\n",
    "- The tricky bit is that your training function might depend on certain parameters,\n",
    "  hyperparameters, that influence the value of your objective function.\n",
    "- You may have a hunch what individual hyperparameters should be, but tuning them all can be difficult.\n",
    "  Even if you can restrict these parameters to a sensible range, it's usually prohibitive to test a wide\n",
    "  range of combinations. Your training function is simply too expensive.\n",
    "\n",
    "What can you do to efficiently sample hyperparameters and get \"good enough\" results on your objective?\n",
    "The field concerned with solving this problem is called _hyperparameter optimization_ (HPO), and Ray Tune has\n",
    "an enormous suite of algorithms for tackling it.\n",
    "Let's look at a first example of Ray Tune used for the situation we just explained.\n",
    "The focus is yet again on Ray and its API, and not on a specific ML task (which we simply simulate for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56743fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::ray_tune[]\n",
    "from ray import tune\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def training_function(config):  # <1>\n",
    "    x, y = config[\"x\"], config[\"y\"]\n",
    "    time.sleep(10)\n",
    "    score = objective(x, y)\n",
    "    tune.report(score=score)  # <2>\n",
    "\n",
    "\n",
    "def objective(x, y):\n",
    "    return math.sqrt((x**2 + y**2)/2)  # <3>\n",
    "\n",
    "\n",
    "result = tune.run(  # <4>\n",
    "    training_function,\n",
    "    config={\n",
    "        \"x\": tune.grid_search([-1, -.5, 0, .5, 1]),  # <5>\n",
    "        \"y\": tune.grid_search([-1, -.5, 0, .5, 1])\n",
    "    })\n",
    "\n",
    "print(result.get_best_config(metric=\"score\", mode=\"min\"))\n",
    "# end::ray_tune[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0ebab",
   "metadata": {},
   "source": [
    "## Model Serving with Ray Serve\n",
    "\n",
    "The last of Ray's high-level libraries we'll discuss specializes on model serving and is simply called _Ray Serve_.\n",
    "To see an example of it in action, you need a trained ML model to serve.\n",
    "Luckily, nowadays you can find many interesting models on the internet that have already been trained for you.\n",
    "For instance, _Hugging Face_ has a variety of models available for you to download directly in Python.\n",
    "The model we'll use is a language model called _GPT-2_ that takes text as input and produces text to\n",
    "continue or complete the input.\n",
    "For example, you can prompt a question and GPT-2 will try to complete it.\n",
    "\n",
    "Serving such a model is a good way to make it accessible.\n",
    "You may not now how to load and run a TensorFlow model on your computer, but you do now how\n",
    "to ask a question in plain English.\n",
    "Model serving hides the implementation details of a solution and lets users focus on providing\n",
    "inputs and understanding outputs of a model.\n",
    "\n",
    "To proceed, make sure to run `pip install transformers` to install the Hugging Face library\n",
    "that has the model we want to use.\n",
    "With that we can now import and start an instance of Ray's `serve` library, load and deploy a GPT-2\n",
    "model and ask it for the meaning of life, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b03fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag::ray_serve[]\n",
    "from ray import serve\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "\n",
    "serve.start()  # <1>\n",
    "\n",
    "\n",
    "@serve.deployment  # <2>\n",
    "def model(request):\n",
    "    language_model = pipeline(\"text-generation\", model=\"gpt2\")  # <3>\n",
    "    query = request.query_params[\"query\"]\n",
    "    return language_model(query, max_length=100)  # <4>\n",
    "\n",
    "\n",
    "model.deploy()  # <5>\n",
    "\n",
    "query = \"What's the meaning of life?\"\n",
    "response = requests.get(f\"http://localhost:8000/model?query={query}\")  # <6>\n",
    "print(response.text)\n",
    "# end::ray_serve[]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('bigdata-2022-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee0e340b373adaa70299d42cd1cb59b0a3467f40584d69eef1fc62bec46809f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
